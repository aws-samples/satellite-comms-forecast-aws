{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586a0559",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SatCom Capacity Time-Series Forecasting with Amazon SageMaker Autopilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bfeb2",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "1. [Setup](#setup)\n",
    "1. [Model Training](#training)\n",
    "1. [Real-Time Predictions (Inference)](#realtime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82c5d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Introduction <a name='introduction'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaadd4e",
   "metadata": {},
   "source": [
    "This notebook uses Amazon SageMaker Autopilot to train a time-series model and produce real time predictions against the trained model. At the top-level, customers provide a set of tabular historical data on S3 and make an API to train a model. Once the model has been trained, you can elect to produce prediction as a batch or via a real-time endpoint. This\n",
    "notebook only provides Real Time Inference. For batch inference see [here](https://github.com/aws/amazon-sagemaker-examples/blob/main/autopilot/autopilot_time_series.ipynb).  </n></n>  As part of the training process, SageMaker Autopilot manages and runs multiple time series models concurrently. All of these models are combined into a single ensembled model which blends the candidate models in a ratio that minimizes forecast error. Customers are provided with metadata and models for the ensemble and all underlying candidate models too. SageMaker Autopilot orchestrates this entire process and provides several artifacts as a result.\n",
    "\n",
    "These artifacts include: \n",
    "- backtest (holdout) forecasts per base model over multiple time windows,\n",
    "- accuracy metrics per base model,\n",
    "- backtest results and accuracy metrics for the ensembled model,\n",
    "- a scaled explainability report displaying the importance of each covariate and static metadata feature.\n",
    "- all model artifacts are provided as well on S3, which can be registered or use for batch/real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee905742",
   "metadata": {},
   "source": [
    "### 2. Setup <a name='setup'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e18236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update boto3 using this method, or your preferred method\n",
    "!pip install --upgrade boto3 --quiet\n",
    "!pip install --upgrade sagemaker --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb440dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime, sleep\n",
    "import datetime\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# MODIFY HERE : \n",
    "# Modify the following values default_bucket to use a bucket of your choosing\n",
    "# Training data is in 1 subfolder whilst sample Real Time Inference files for prediction in another\n",
    "# training inputs need to be in a separate folder from training outputs\n",
    "bucket = 'forecast-satcom-autopilot-capacity'\n",
    "train_prefix = 'dataset/train'\n",
    "train_output_prefix = 'dataset/train_output'\n",
    "\n",
    "# The prediction file is a small subset of the training data, again without the target variable (mHz) \n",
    "# values for the most recent day(s)\n",
    "# We can generate that subset prediction csv via the same satcom-timeseries-autopilot-gen-fxn lambda\n",
    "# Use mode = 'inf' instead of 'train' in the env variables (and set the startday or startmonth later)\n",
    "rtinf_prefix = 'dataset/rtinf'\n",
    "rtinf_satcom_pred_file = \"satcom-autopilot-cap_1723517598.csv\"   # replace with your generated filename\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "# This is the client we will use to interact with SageMaker Autopilot\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a705a8d7",
   "metadata": {},
   "source": [
    "IMPORTANT: When training a model, your input data can contain a mixture of covariate and static item metadata. Take care to create future-dated rows that extend to the end of your prediction horizon. In the future-dated rows, carry your static item metadata and expected covariate values. Future-dated target-value (y) should be empty. You can observe the data programmatically or in a text editor as an example.\n",
    "\n",
    "The structure of the CSV file provided is as follows:\n",
    "- timestamp (required, TimestampAttributeName)\n",
    "- airpressure (covariate)\n",
    "- beam (required: ItemIdentifierAttributeName)\n",
    "- dayofweek (covariate)\n",
    "- hourofday (covariate)\n",
    "- mHz (required: TargetAttributeName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7109c3c",
   "metadata": {},
   "source": [
    "### 3. Model Training <a name='training'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a80d3",
   "metadata": {},
   "source": [
    "Establish an AutoML training job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e53cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp_suffix = strftime(\"%Y%m%d-%H%M%S\", gmtime())\n",
    "auto_ml_job_name = \"ts-\" + timestamp_suffix\n",
    "print(\"AutoMLJobName: \" + auto_ml_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9633d",
   "metadata": {},
   "source": [
    "Define training job specifications. More information about [create_auto_ml_job_v2](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_auto_ml_job_v2.html) can be found in our SageMaker documentation.</n></n>This JSON body leverages the built-in sample data schema. Please consult the documentation to understand how to alter the parameters for your unique schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d88928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data_config = [\n",
    "    {  'ChannelType': 'training',\n",
    "            'ContentType': 'text/csv;header=present',\n",
    "            'CompressionType': 'None',\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': 's3://{}/{}/'.format(bucket, train_prefix),\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "output_data_config = {'S3OutputPath': 's3://{}/{}/'.format(bucket, train_output_prefix)}\n",
    "\n",
    "optimizaton_metric_config = {'MetricName': 'AverageWeightedQuantileLoss'}\n",
    "\n",
    "automl_problem_type_config ={\n",
    "        'TimeSeriesForecastingJobConfig': {\n",
    "            'ForecastFrequency': '10min',\n",
    "            'ForecastHorizon': 144,\n",
    "            'ForecastQuantiles': ['p50','p70','p90'],\n",
    "            'TimeSeriesConfig': {\n",
    "                'TargetAttributeName': 'mHz',\n",
    "                'TimestampAttributeName': 'timestamp',\n",
    "                'ItemIdentifierAttributeName': 'beam',\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "automl_train_tag=[\n",
    "    {\n",
    "        'Key': 'Name',\n",
    "        'Value': 'satcom_forecast_train'\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1460e",
   "metadata": {},
   "source": [
    "With parameters now defined, invoke the [training job](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_auto_ml_job_v2.html) and monitor for its completion. You can expect the training to take about 60-90 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bae8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm.create_auto_ml_job_v2(\n",
    "    AutoMLJobName=auto_ml_job_name,\n",
    "    AutoMLJobInputDataConfig=input_data_config,\n",
    "    OutputDataConfig=output_data_config,\n",
    "    AutoMLProblemTypeConfig = automl_problem_type_config,\n",
    "    AutoMLJobObjective=optimizaton_metric_config,\n",
    "    RoleArn=role,\n",
    "    Tags=automl_train_tag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae7800",
   "metadata": {},
   "source": [
    "Next, we demonstrate a looping mechanism to query (monitor) job status. When the status is ```Completed```, you may review the accuracy of the model and decide whether to perform inference on a batch or real-time API basis as described in this notebook. Please consult documentation for [describe_auto_ml_job_v2](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/describe_auto_ml_job_v2.html) as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2266f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "describe_response = sm.describe_auto_ml_job_v2(AutoMLJobName=auto_ml_job_name)\n",
    "job_run_status = describe_response[\"AutoMLJobStatus\"]\n",
    "\n",
    "while job_run_status not in (\"Failed\", \"Completed\", \"Stopped\"):\n",
    "    describe_response = sm.describe_auto_ml_job_v2(AutoMLJobName=auto_ml_job_name)\n",
    "    job_run_status = describe_response[\"AutoMLJobStatus\"]\n",
    "\n",
    "    print(\n",
    "       datetime.datetime.now(), describe_response[\"AutoMLJobStatus\"] + \" - \" + describe_response[\"AutoMLJobSecondaryStatus\"]\n",
    "    )\n",
    "    sleep(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09755b84",
   "metadata": {},
   "source": [
    "Once training is completed, you can use the describe function to iterate over model leaderboard results. Below is an example to use the best candidate in the subsequent inference phase. Please consult our documentation on [create_model](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_model.html) as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3630ece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_candidate = sm.describe_auto_ml_job_v2(AutoMLJobName=auto_ml_job_name)['BestCandidate']\n",
    "best_candidate_containers = best_candidate['InferenceContainers'] \n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "\n",
    "response = sm.create_model(\n",
    "   ModelName = best_candidate_name,\n",
    "   ExecutionRoleArn = role,\n",
    "   Containers = best_candidate_containers\n",
    ")\n",
    "\n",
    "print('BestCandidateName:',best_candidate_name)\n",
    "print('BestCandidateContainers:',best_candidate_containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18ed64",
   "metadata": {},
   "source": [
    "### 4. Real-Time Predictions (Inference) <a name='realtime'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f0f40",
   "metadata": {},
   "source": [
    "If you want to perform real-time inference, review this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb00971",
   "metadata": {},
   "source": [
    "Define a model, endpoint configuration and endpoint name using the candidate metadata. Consult [create_endpoint_config](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_endpoint_config.html) documentation for more detail. Additionally, please adjust the ```InstanceType``` and ```InitialInstanceCount``` according to need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ae233",
   "metadata": {},
   "source": [
    "IMPORTANT: The data you supply for inference must have at least four valid historical values for each time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32faec55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"epc-{best_candidate_name}\"\n",
    "endpoint_name = f\"ep-{best_candidate_name}\"\n",
    "\n",
    "endpoint_tag=[\n",
    "    {\n",
    "        'Key': 'Name',\n",
    "        'Value': 'satcom_forecast_endpoint'\n",
    "    }\n",
    "]\n",
    "\n",
    "endpoint_config_tag=[\n",
    "    {\n",
    "        'Key': 'Name',\n",
    "        'Value': 'satcom_forecast_endpoint_config'\n",
    "    }\n",
    "]\n",
    "\n",
    "production_variants = [\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m5.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": best_candidate_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "epc_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=production_variants,\n",
    "    Tags=endpoint_config_tag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508af18c",
   "metadata": {},
   "source": [
    "Next, you can deploy a real-time endpoint using the [create_endpoint](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_endpoint.html\n",
    ") API. See the documentation for more details and options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b3ef40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm.create_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    Tags=endpoint_tag\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea522a8",
   "metadata": {},
   "source": [
    "Poll for endpoint to become ready to serve (InService)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157f6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "describe_response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "job_run_status = describe_response[\"EndpointStatus\"]\n",
    "\n",
    "while job_run_status not in (\"Failed\", \"InService\", \"Stopped\"):\n",
    "    describe_response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    job_run_status = describe_response[\"EndpointStatus\"]\n",
    "\n",
    "    print(\n",
    "       datetime.datetime.now(), describe_response[\"EndpointStatus\"])\n",
    "    sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482cadb",
   "metadata": {},
   "source": [
    "The next cells help demonstrate opening a CSV file from S3 for inference. Alternately, this data could come from a database query or live application. In this example, the data is loaded into a Python memory object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf5654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A small sample file that corresponds to the sample training dataset and trained model schema\n",
    "\n",
    "rt_satcom_pred = \"s3://\" + bucket + \"/\" + rtinf_prefix + \"/\" + rtinf_satcom_pred_file\n",
    "print(rt_satcom_pred)\n",
    "\n",
    "#!aws s3 cp s3://amazon-forecast-samples/autopilot/real-time-payload.csv ./real-time-payload.csv\n",
    "!aws s3 cp {rt_satcom_pred} ./{rtinf_satcom_pred_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d441581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#input_file = './real-time-payload.csv'\n",
    "input_file = f\"{'./'}{rtinf_satcom_pred_file}\"\n",
    "print(input_file)\n",
    "f=open(input_file,'r')\n",
    "inference_data = f.read()\n",
    "f.close()\n",
    "\n",
    "# print first few chars to sanity check inference_data input for RT prediction\n",
    "print (inference_data[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d215a",
   "metadata": {},
   "source": [
    "Method to instantiate SageMaker runtime client and [invoke endpoint](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime/client/invoke_endpoint.html). Please note the guidance given in the documentation page which says the response must be within 60 seconds of invocation. Response times are a function of payload size. You should take care to provide history for single time-series, and carefully testing the ability to perform predictions for more than one time-series at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d467672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1057d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm_client.invoke_endpoint(\n",
    "    EndpointName= endpoint_name,\n",
    "    Body= inference_data,\n",
    "    ContentType = 'text/csv')\n",
    "\n",
    "prediction = response['Body'].read().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cee341",
   "metadata": {},
   "source": [
    "At this point, the results from the real-time API call are loaded into a variable called ```prediction```. You have several options on what you do with the results. A few are given here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d9b258",
   "metadata": {},
   "source": [
    "Optional: Example of saving the resulting real-time predictions to a local filesystem. Carefully plan your naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e8066-005c-4fb5-b995-3282aa8882e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt_1 = datetime.datetime.now()\n",
    "dt_secs = int(dt_1.timestamp())\n",
    "print(dt_secs)\n",
    "\n",
    "output_file = f\"{'rt-satcom-pred-output'}_{dt_secs}{'.csv'}\"\n",
    "print(output_file)\n",
    "\n",
    "f=open(output_file,'w')\n",
    "f.write(prediction)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd6b600",
   "metadata": {},
   "source": [
    "Optional: Example of saving the resulting real-time predictions to a S3 object. Carefully plan your naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ff6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#output_file = 'real-time-prediction-output.csv'\n",
    "key='{}/results/{}'.format(rtinf_prefix, output_file)\n",
    "\n",
    "print(\"SageMaker Autopilot Real Time Inference result. Bucket: \" + bucket + \". Data: \" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b8eda-8d80-431f-aa23-de51cf3e58a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.put_object(Body=prediction, Bucket=bucket, Key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98e727",
   "metadata": {},
   "source": [
    "#### Cleanup Real-time Endpoint Resources\n",
    "\n",
    "As needed, you can stop the endpoint and related billing costs as follows. When you need the endpoint again, you can follow the deployment steps again. Ideally, at a future time, another newer model is trained and able to be deployed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078dd721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ceaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de2bc75",
   "metadata": {},
   "source": [
    "Caution: Do not delete the model if you intend on testing batch transformation too. If you do delete the model, you may redeploy it as long as the model artifact exists on S3. The next cell provides the container and S3 location for your best candidate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.delete_model(ModelName=best_candidate_name)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
